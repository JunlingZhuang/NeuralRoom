{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flask import Flask, request, jsonify\n",
    "import os\n",
    "import sys\n",
    "\n",
    "sys.path.append(\"./api\")\n",
    "from api.scripts.visualize_box_version import (\n",
    "    prepare_dataset_and_model,\n",
    "    generate_queried_unit_mesh,\n",
    ")\n",
    "\n",
    "args_location = \"api/test/new_prior_1500/args.json\"\n",
    "ckpt_link = (\n",
    "    \"https://drive.google.com/file/d/1-YjqqoAnv9_FD288mRYIGoNW75CcJaUR/view?usp=sharing\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\neuralroom_nextjs\\api\\model\\VAE_prior.py:50: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  torch.load(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model loaded!\n",
      "training statistics collected\n"
     ]
    }
   ],
   "source": [
    "args, model, dataset, _, _ = prepare_dataset_and_model(\n",
    "    args_location=args_location, ckpt_epoch=400, ckpt_link=ckpt_link\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatCompletionMessage(content='Step 1:  Determine Headcounts and Basic Room Requirements\\n-Occupant: 1 person.\\n-Bedrooms: 1 bedroom.\\n-Bathrooms: 1 bathroom.\\n-Basic room list: [\\'bedroom\\', \\'bathroom\\']\\n\\nStep 2:  Additional rooms based on lifestyle\\n-Works from home: include a \\'library\\' for workspace.\\n-Enjoys painting: since \\'artstudio\\' is not in the predefined list, use \\'library\\' also to serve as an art space.\\n-Common areas: \\'livingroom\\', \\'kitchen\\'.\\n-Complete room list: [\\'bedroom\\', \\'bathroom\\', \\'livingroom\\', \\'kitchen\\', \\'library\\']\\n\\nStep 3: Assign Indexes\\n{\\n  \\'0\\': \\'bedroom\\',\\n  \\'1\\': \\'bathroom\\',\\n  \\'2\\': \\'livingroom\\',\\n  \\'3\\': \\'kitchen\\',\\n  \\'4\\': \\'library\\'\\n}\\n\\nStep 4: Infer Adjacency\\n-Bedroom connected to bathroom: (0, 1).\\n-Bedroom connected to library (workspace and art space): (0, 4).\\n-Living room connected to kitchen: (2, 3).\\n-Living room connected to library: (2, 4).\\n-Adjacency List: [(0, 1), (0, 4), (2, 3), (2, 4)]\\n\\nStep 5:\\n{\\n  \"Room List\": {\\n    \"0\": \"bedroom\",\\n    \"1\": \"bathroom\",\\n    \"2\": \"livingroom\",\\n    \"3\": \"kitchen\",\\n    \"4\": \"library\"\\n  },\\n  \"Adjacency List\": [(0, 1), (0, 4), (2, 3), (2, 4)]\\n}', refusal=None, role='assistant', function_call=None, tool_calls=None)\n"
     ]
    }
   ],
   "source": [
    "from api.LLM.prompt_basic import make_basic_input_prompt, make_basic_sysprompt\n",
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI()\n",
    "description = \"A layout designed for a single professional who works from home and enjoys painting. They need a dedicated workspace and an art studio. \"\n",
    "sysprompt = make_basic_sysprompt()\n",
    "input = make_basic_input_prompt(description)\n",
    "\n",
    "completion = client.chat.completions.create(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": sysprompt},\n",
    "        {\"role\": \"user\", \"content\": input},\n",
    "    ],\n",
    ")\n",
    "print(completion.choices[0].message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step1=\"Occupants: 4 people (parents and two children). Bedrooms: Parents share one bedroom; each child has their own bedroom. Total bedrooms = 3. Bathrooms: For 4 people, 1 bathroom is suitable but having 2 bathrooms could provide additional convenience. Basic room list: ['bedroom', 'bedroom', 'bedroom', 'bathroom', 'bathroom']\" step2=\"Common areas: 'livingroom', 'kitchen', 'diningroom'. Circulation space: 'circulation'. Complete room list: ['bedroom', 'bedroom', 'bedroom', 'bathroom', 'bathroom', 'livingroom', 'kitchen', 'diningroom', 'circulation']\" step3=\"Assign Indexes {'0': 'bedroom', '1': 'bedroom', '2': 'bedroom', '3': 'bathroom', '4': 'bathroom', '5': 'livingroom', '6': 'kitchen', '7': 'diningroom', '8': 'circulation'}\" step4='Bedrooms connected to bathrooms: (0, 3), (1, 4), (2, 4). Bedrooms connected to circulation: (0, 8), (1, 8), (2, 8). Circulation connected to living room: (8, 5). Living room connected to kitchen and dining room: (5, 6), (5, 7). Kitchen connected to dining room: (6, 7). Adjacency List: [(0, 3), (1, 4), (2, 4), (0, 8), (1, 8), (2, 8), (8, 5), (5, 6), (5, 7), (6, 7)]' step5=RoomGraph(roomlist=[Room(index=0, room_type='bedroom'), Room(index=1, room_type='bedroom'), Room(index=2, room_type='bedroom'), Room(index=3, room_type='bathroom'), Room(index=4, room_type='bathroom'), Room(index=5, room_type='livingroom'), Room(index=6, room_type='kitchen'), Room(index=7, room_type='diningroom'), Room(index=8, room_type='circulation')], adjacencylist=[RoomAdjacency(room1=0, room2=3), RoomAdjacency(room1=1, room2=4), RoomAdjacency(room1=2, room2=4), RoomAdjacency(room1=0, room2=8), RoomAdjacency(room1=1, room2=8), RoomAdjacency(room1=2, room2=8), RoomAdjacency(room1=8, room2=5), RoomAdjacency(room1=5, room2=6), RoomAdjacency(room1=5, room2=7), RoomAdjacency(room1=6, room2=7)])\n"
     ]
    }
   ],
   "source": [
    "from pydantic import BaseModel\n",
    "from typing import List, Tuple, Dict\n",
    "\n",
    "\n",
    "from openai import OpenAI\n",
    "\n",
    "\n",
    "client = OpenAI()\n",
    "\n",
    "\n",
    "class RoomAdjacency(BaseModel):\n",
    "    room1: int\n",
    "    room2: int\n",
    "\n",
    "\n",
    "class Room(BaseModel):\n",
    "    index: int\n",
    "    room_type: str\n",
    "\n",
    "\n",
    "class RoomGraph(BaseModel):\n",
    "    roomlist: List[Room]\n",
    "    adjacencylist: List[RoomAdjacency]\n",
    "\n",
    "\n",
    "class OutputGraph(BaseModel):\n",
    "    step1: str\n",
    "    step2: str\n",
    "    step3: str\n",
    "    step4: str\n",
    "    step5: RoomGraph\n",
    "\n",
    "\n",
    "client = OpenAI()\n",
    "description = \"help me design a layout for a family of 4 -- one couple and two children. The couple shares a bedroom, and the each child has own bedroom\"\n",
    "sysprompt = make_basic_sysprompt()\n",
    "input = make_basic_input_prompt(description)\n",
    "\n",
    "\n",
    "completion = client.beta.chat.completions.parse(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": sysprompt},\n",
    "        {\"role\": \"user\", \"content\": input},\n",
    "    ],\n",
    "    response_format=OutputGraph,\n",
    ")\n",
    "\n",
    "\n",
    "event = completion.choices[0].message.parsed\n",
    "print(event)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3, 3, 3, 1, 1, 13, 11, 9, 6]\n",
      "[[0, 3, 3], [1, 3, 4], [2, 3, 4], [0, 3, 8], [1, 3, 8], [2, 3, 8], [8, 3, 5], [5, 3, 6], [5, 3, 7], [6, 3, 7]]\n"
     ]
    }
   ],
   "source": [
    "gt_dir = \"api/test/new_prior_1500_GT\"\n",
    "class_file = gt_dir + \"/classes.txt\"\n",
    "\n",
    "\n",
    "def process_LLM_output(classes_dict, rel_dict, LLM_output=None):\n",
    "    \"\"\"\n",
    "    input\n",
    "    - class_dic: the obj classes dict from the dataset\n",
    "    - rel_dic: the relationship dict from the dataset\n",
    "    - LLM_output: the raw output of LLM, including step1,step2,step3\n",
    "\n",
    "    return\n",
    "    - room_list: a list of room class integer id\n",
    "    - adj_list: a list of room adjcency tuple, (room1 index, room2 index)\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    room_graph = LLM_output.step5\n",
    "    room_str_list = [room.room_type for room in room_graph.roomlist]\n",
    "    room_list = [classes_dict[rm] for rm in room_str_list]\n",
    "    adj_id = rel_dict.get(\"adjacent to\")\n",
    "    adj_list = [[adj.room1, adj_id, adj.room2] for adj in room_graph.adjacencylist]\n",
    "    return room_list, adj_list\n",
    "\n",
    "\n",
    "classes_dict = dataset.classes\n",
    "rel_dict = dataset.relationships_dict\n",
    "room_list, adj_list = process_LLM_output(\n",
    "    classes_dict=classes_dict, rel_dict=rel_dict, LLM_output=event\n",
    ")\n",
    "\n",
    "print(room_list)\n",
    "print(adj_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\neuralroom_nextjs\\api\\model\\VAE_prior.py:50: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  torch.load(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model loaded!\n",
      "training statistics collected\n",
      "model initialized\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "sys.path.append(\"api/\")\n",
    "\n",
    "from api.scripts.visualize_box_version import (\n",
    "    prepare_dataset_and_model,\n",
    "    generate_queried_unit_mesh,\n",
    ")\n",
    "\n",
    "\n",
    "gt_dir = \"api/test/new_prior_1500_GT\"\n",
    "args_location = \"api/test/new_prior_1500/args.json\"\n",
    "ckpt_link = (\n",
    "    \"https://drive.google.com/file/d/1-YjqqoAnv9_FD288mRYIGoNW75CcJaUR/view?usp=sharing\"\n",
    ")\n",
    "# model and dataset initialized when webpage mounted\n",
    "args, model, dataset, _, _ = prepare_dataset_and_model(\n",
    "    args_location=args_location, ckpt_epoch=400, ckpt_link=ckpt_link\n",
    ")\n",
    "print(\"model initialized\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'_unit_': 0, 'bathroom': 1, 'bed': 2, 'bedroom': 3, 'cabinet': 4, 'chair': 5, 'circulation': 6, 'courtyard': 7, 'desk': 8, 'diningroom': 9, 'empty': 10, 'kitchen': 11, 'library': 12, 'livingroom': 13, 'nightstand': 14, 'service': 15, 'sofa': 16, 'storage': 17, 'table': 18, 'wardrobe': 19}\n"
     ]
    }
   ],
   "source": [
    "print(dataset.classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index out of range in self",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m model_file_path \u001b[38;5;241m=\u001b[39m \u001b[43mgenerate_queried_unit_mesh\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_objs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mroom_list\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_triples\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43madj_list\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43munit_box\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_dataset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      8\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[1;32me:\\neuralroom_nextjs\\api\\scripts\\visualize_box_version.py:239\u001b[0m, in \u001b[0;36mgenerate_queried_unit_mesh\u001b[1;34m(input_objs, input_triples, unit_box, args, model, train_dataset)\u001b[0m\n\u001b[0;32m    232\u001b[0m dec_objs, dec_triples, dec_unit_box \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    233\u001b[0m     dec_objs\u001b[38;5;241m.\u001b[39mto(device),\n\u001b[0;32m    234\u001b[0m     dec_triples\u001b[38;5;241m.\u001b[39mto(device),\n\u001b[0;32m    235\u001b[0m     dec_unit_box\u001b[38;5;241m.\u001b[39mto(device),\n\u001b[0;32m    236\u001b[0m )\n\u001b[0;32m    237\u001b[0m seed \u001b[38;5;241m=\u001b[39m random\u001b[38;5;241m.\u001b[39mrandint(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m10000\u001b[39m)\n\u001b[1;32m--> 239\u001b[0m new_objs, new_triples, new_obj2pidx, boxes_pred, angles_pred \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvae_box\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minfer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    240\u001b[0m \u001b[43m    \u001b[49m\u001b[43mroom_nodes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdec_objs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    241\u001b[0m \u001b[43m    \u001b[49m\u001b[43mroom_triples\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdec_triples\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    242\u001b[0m \u001b[43m    \u001b[49m\u001b[43munit_box\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdec_unit_box\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    243\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrandom_seed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    244\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpoint_classes_idx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_dataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpoint_classes_idx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    245\u001b[0m \u001b[43m    \u001b[49m\u001b[43mwith_categories\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcategorize_latents\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    246\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    248\u001b[0m angle_num \u001b[38;5;241m=\u001b[39m args\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mangle_num\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m24\u001b[39m)\n\u001b[0;32m    250\u001b[0m angles_pred \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m180\u001b[39m \u001b[38;5;241m+\u001b[39m (torch\u001b[38;5;241m.\u001b[39margmax(angles_pred, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, keepdim\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m) \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m*\u001b[39m (\n\u001b[0;32m    251\u001b[0m     \u001b[38;5;241m360\u001b[39m \u001b[38;5;241m/\u001b[39m angle_num\n\u001b[0;32m    252\u001b[0m )\n",
      "File \u001b[1;32me:\\neuralroom_nextjs\\api\\model\\VAEGAN_V5BOX.py:596\u001b[0m, in \u001b[0;36mSg2ScVAEModel.infer\u001b[1;34m(self, room_nodes, room_triples, unit_box, device, random_seed, point_classes_idx, with_categories)\u001b[0m\n\u001b[0;32m    587\u001b[0m unit_z \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msample_latents(\n\u001b[0;32m    588\u001b[0m     torch\u001b[38;5;241m.\u001b[39mtensor([\u001b[38;5;241m0\u001b[39m])\u001b[38;5;241m.\u001b[39mto(device),\n\u001b[0;32m    589\u001b[0m     device\u001b[38;5;241m=\u001b[39mdevice,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    592\u001b[0m     with_categories\u001b[38;5;241m=\u001b[39mwith_categories,\n\u001b[0;32m    593\u001b[0m )\n\u001b[0;32m    594\u001b[0m \u001b[38;5;66;03m# no grad, reconstruct full graph\u001b[39;00m\n\u001b[0;32m    595\u001b[0m all_nodes, all_triples, all_zs, all_obj2pidx, roomunit_idxs, fur_idxs \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m--> 596\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreconstruct_full_graph\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    597\u001b[0m \u001b[43m        \u001b[49m\u001b[43mroom_nodes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mroom_nodes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    598\u001b[0m \u001b[43m        \u001b[49m\u001b[43mroom_triples\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mroom_triples\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    599\u001b[0m \u001b[43m        \u001b[49m\u001b[43mroom_zs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mroom_zs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    600\u001b[0m \u001b[43m        \u001b[49m\u001b[43munit_box\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43munit_box\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    601\u001b[0m \u001b[43m        \u001b[49m\u001b[43munit_z\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43munit_z\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    602\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    603\u001b[0m )\n\u001b[0;32m    605\u001b[0m roomunit_nodes \u001b[38;5;241m=\u001b[39m all_nodes[roomunit_idxs]\n\u001b[0;32m    606\u001b[0m all_unit_box \u001b[38;5;241m=\u001b[39m unit_box[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mrepeat((all_zs\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m), \u001b[38;5;241m1\u001b[39m))\u001b[38;5;241m.\u001b[39mto(device)\n",
      "File \u001b[1;32me:\\neuralroom_nextjs\\api\\model\\VAEGAN_V5BOX.py:836\u001b[0m, in \u001b[0;36mSg2ScVAEModel.reconstruct_full_graph\u001b[1;34m(self, room_nodes, room_triples, room_zs, unit_box, unit_z)\u001b[0m\n\u001b[0;32m    834\u001b[0m unitbox_vecs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39munit_box_embeddings_pr(unit_box)\n\u001b[0;32m    835\u001b[0m \u001b[38;5;66;03m# room semantic features\u001b[39;00m\n\u001b[1;32m--> 836\u001b[0m room_sem_vecs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msem_embeddings_rm_pr\u001b[49m\u001b[43m(\u001b[49m\u001b[43mroom_nodes\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    837\u001b[0m room_vecs \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat([room_sem_vecs, unitbox_vecs, room_zs], dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)  \u001b[38;5;66;03m# 2D\u001b[39;00m\n\u001b[0;32m    838\u001b[0m fur_z, fur_edges \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprior_sampler\u001b[38;5;241m.\u001b[39msample_fur_nodes(room_vecs)  \u001b[38;5;66;03m# 2 lists\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\moumo\\anaconda3\\envs\\neuralroom\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\moumo\\anaconda3\\envs\\neuralroom\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\moumo\\anaconda3\\envs\\neuralroom\\Lib\\site-packages\\torch\\nn\\modules\\sparse.py:164\u001b[0m, in \u001b[0;36mEmbedding.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    163\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 164\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membedding\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    165\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_norm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    166\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnorm_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscale_grad_by_freq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msparse\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\moumo\\anaconda3\\envs\\neuralroom\\Lib\\site-packages\\torch\\nn\\functional.py:2267\u001b[0m, in \u001b[0;36membedding\u001b[1;34m(input, weight, padding_idx, max_norm, norm_type, scale_grad_by_freq, sparse)\u001b[0m\n\u001b[0;32m   2261\u001b[0m     \u001b[38;5;66;03m# Note [embedding_renorm set_grad_enabled]\u001b[39;00m\n\u001b[0;32m   2262\u001b[0m     \u001b[38;5;66;03m# XXX: equivalent to\u001b[39;00m\n\u001b[0;32m   2263\u001b[0m     \u001b[38;5;66;03m# with torch.no_grad():\u001b[39;00m\n\u001b[0;32m   2264\u001b[0m     \u001b[38;5;66;03m#   torch.embedding_renorm_\u001b[39;00m\n\u001b[0;32m   2265\u001b[0m     \u001b[38;5;66;03m# remove once script supports set_grad_enabled\u001b[39;00m\n\u001b[0;32m   2266\u001b[0m     _no_grad_embedding_renorm_(weight, \u001b[38;5;28minput\u001b[39m, max_norm, norm_type)\n\u001b[1;32m-> 2267\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membedding\u001b[49m\u001b[43m(\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpadding_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscale_grad_by_freq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msparse\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mIndexError\u001b[0m: index out of range in self"
     ]
    }
   ],
   "source": [
    "model_file_path = generate_queried_unit_mesh(\n",
    "    input_objs=room_list,\n",
    "    input_triples=adj_list,\n",
    "    unit_box=[3, 3, 5],\n",
    "    args=args,\n",
    "    model=model,\n",
    "    train_dataset=dataset,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "neuralroom",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
