{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flask import Flask, request, jsonify\n",
    "import os\n",
    "import sys\n",
    "\n",
    "sys.path.append(\"./api\")\n",
    "from api.scripts.visualize_box_version import (\n",
    "    prepare_dataset_and_model,\n",
    "    generate_queried_unit_mesh,\n",
    ")\n",
    "\n",
    "args_location = \"api/test/new_prior_1500/args.json\"\n",
    "ckpt_link = (\n",
    "    \"https://drive.google.com/file/d/1-YjqqoAnv9_FD288mRYIGoNW75CcJaUR/view?usp=sharing\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_objs = [3, 13, 11]\n",
    "input_triples = [\n",
    "    [1, 3, 0],\n",
    "    [2, 3, 1],\n",
    "]\n",
    "unit_box = [3, 3, 5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model loaded!\n",
      "training statistics collected\n"
     ]
    }
   ],
   "source": [
    "args, model, dataset, _, _ = prepare_dataset_and_model(\n",
    "    args_location=args_location, ckpt_epoch=400, ckpt_link=ckpt_link\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['_unit_\\n', 'chair\\n', 'bathroom\\n', 'bed\\n', 'bedroom\\n', 'cabinet\\n', 'chair\\n', 'sofa\\n', 'chair\\n', 'circulation\\n', 'table\\n', 'courtyard\\n', 'desk\\n', 'chair\\n', 'table\\n', 'diningroom\\n', 'bed\\n', 'empty\\n', 'bed\\n', 'kitchen\\n', 'sofa\\n', 'library\\n', 'livingroom\\n', 'chair\\n', 'sofa\\n', 'sofa\\n', 'nightstand\\n', 'table\\n', 'service\\n', 'bed\\n', 'sofa\\n', 'storage\\n', 'table\\n', 'wardrobe\\n']\n"
     ]
    }
   ],
   "source": [
    "print(dataset.vocab[\"full_object_idx_to_name\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bed\n",
      "bathroom\n",
      "bedroom\n",
      "cabinet\n",
      "chair\n",
      "chair\n",
      "_unit_\n"
     ]
    }
   ],
   "source": [
    "detailed_obj_class = list(dataset.classes.keys())\n",
    "for idx in input_objs:\n",
    "    print(detailed_obj_class[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['_unit_', 'bathroom', 'bed', 'bedroom', 'cabinet', 'chair', 'circulation', 'courtyard', 'desk', 'diningroom', 'empty', 'kitchen', 'library', 'livingroom', 'nightstand', 'service', 'sofa', 'storage', 'table', 'wardrobe']\n",
      "tensor([ 2,  1,  3,  4,  5,  5,  0,  2, 14,  2,  8,  5,  2,  5, 14,  5,  5, 16,\n",
      "         0])\n",
      "tensor([ 0,  1,  2,  3,  4,  5,  6,  2,  2,  2,  2,  2,  6,  6,  6,  6,  6,  6,\n",
      "        18])\n",
      "bed\n",
      "bathroom\n",
      "bedroom\n",
      "cabinet\n",
      "chair\n",
      "chair\n",
      "_unit_\n",
      "_unit_\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'bed'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m model_file_path \u001b[38;5;241m=\u001b[39m \u001b[43mgenerate_queried_unit_mesh\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_objs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_objs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_triples\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_triples\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43munit_box\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43munit_box\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_dataset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      8\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[1;32me:\\neuralroom_nextjs\\api\\scripts\\visualize_box_version.py:335\u001b[0m, in \u001b[0;36mgenerate_queried_unit_mesh\u001b[1;34m(input_objs, input_triples, unit_box, args, model, train_dataset)\u001b[0m\n\u001b[0;32m    333\u001b[0m     fur_cat \u001b[38;5;241m=\u001b[39m json\u001b[38;5;241m.\u001b[39mload(file)\n\u001b[0;32m    334\u001b[0m \u001b[38;5;66;03m# trimesh mesh object\u001b[39;00m\n\u001b[1;32m--> 335\u001b[0m meshes, _, _ \u001b[38;5;241m=\u001b[39m \u001b[43mcreate_scene_meshes\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    336\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnew_objs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    337\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnew_obj2pidx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    338\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdenormalized_boxes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    339\u001b[0m \u001b[43m    \u001b[49m\u001b[43mangles_pred\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    340\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdetailed_obj_class\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    341\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfur_cat\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    342\u001b[0m \u001b[43m    \u001b[49m\u001b[43msdf_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    343\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretrieve_sdf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# export box only meshes\u001b[39;49;00m\n\u001b[0;32m    344\u001b[0m \u001b[43m    \u001b[49m\u001b[43mceiling_and_floor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    345\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    346\u001b[0m exp_dir \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(args[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexp\u001b[39m\u001b[38;5;124m\"\u001b[39m], \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmesh\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    347\u001b[0m mesh_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m.obj\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(data\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mscan_id\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n",
      "File \u001b[1;32me:\\neuralroom_nextjs\\./api\\helpers\\viz_util.py:842\u001b[0m, in \u001b[0;36mcreate_scene_meshes\u001b[1;34m(dec_objs_grained, obj_to_pidx, denormalized_boxes, angles_pred, detailed_obj_class, fur_cat, sdf_dir, retrieve_sdf, ceiling_and_floor, substract_room)\u001b[0m\n\u001b[0;32m    840\u001b[0m         unit_id \u001b[38;5;241m=\u001b[39m room_id\n\u001b[0;32m    841\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 842\u001b[0m         hier_id \u001b[38;5;241m=\u001b[39m \u001b[43mROOM_HIER_MAP\u001b[49m\u001b[43m[\u001b[49m\u001b[43mroom_class\u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m    843\u001b[0m         room_hier_dic[room_id] \u001b[38;5;241m=\u001b[39m hier_id\n\u001b[0;32m    844\u001b[0m room_idxs\u001b[38;5;241m.\u001b[39mremove(unit_id)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'bed'"
     ]
    }
   ],
   "source": [
    "model_file_path = generate_queried_unit_mesh(\n",
    "    input_objs=input_objs,\n",
    "    input_triples=input_triples,\n",
    "    unit_box=unit_box,\n",
    "    args=args,\n",
    "    model=model,\n",
    "    train_dataset=dataset,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 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\n",
    "# openai project key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatCompletionMessage(content=\"Output:\\n  \\nStep 1: ['bedroom', 'bedroom', 'bedroom', 'bathroom', 'bathroom']  \\n \\nStep 2: ['bedroom', 'bedroom', 'bedroom', 'bathroom', 'bathroom', 'living room', 'kitchen', 'dining room']  \\n  \\nStep 3: [(0,3), (1,4), (2,4), (3,5), (3,6), (5,7)]  \", refusal=None, role='assistant', function_call=None, tool_calls=None)\n"
     ]
    }
   ],
   "source": [
    "from api.LLM.prompt_basic import make_basic_input_prompt, make_basic_sysprompt\n",
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI()\n",
    "description = \"help me design a layout for a family of 4 -- one couple and two children. The couple shares a bedroom, and the each child has own bedroom\"\n",
    "sysprompt = make_basic_sysprompt()\n",
    "input = make_basic_input_prompt(description)\n",
    "\n",
    "completion = client.chat.completions.create(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": sysprompt},\n",
    "        {\"role\": \"user\", \"content\": input},\n",
    "    ],\n",
    ")\n",
    "print(completion.choices[0].message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel\n",
    "from typing import List, Tuple\n",
    "\n",
    "\n",
    "from openai import OpenAI\n",
    "\n",
    "\n",
    "client = OpenAI()\n",
    "\n",
    "\n",
    "class RoomAdjacency(BaseModel):\n",
    "    room1: int\n",
    "    room2: int\n",
    "\n",
    "\n",
    "class OutputGraph(BaseModel):\n",
    "    step1: List[str]\n",
    "    step2: List[str]\n",
    "    step3: List[RoomAdjacency]\n",
    "\n",
    "\n",
    "client = OpenAI()\n",
    "description = \"help me design a layout for a family of 4 -- one couple and two children. The couple shares a bedroom, and the each child has own bedroom\"\n",
    "sysprompt = make_basic_sysprompt()\n",
    "input = make_basic_input_prompt(description)\n",
    "\n",
    "\n",
    "completion = client.beta.chat.completions.parse(\n",
    "    model=\"gpt-4o-2024-08-06\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": sysprompt},\n",
    "        {\"role\": \"user\", \"content\": input},\n",
    "    ],\n",
    "    response_format=OutputGraph,\n",
    ")\n",
    "\n",
    "\n",
    "event = completion.choices[0].message.parsed\n",
    "print(event)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4, 4, 4, 2, 2, 22, 19, 15]\n",
      "[[0, 3, 3], [1, 3, 3], [2, 3, 4], [0, 3, 5], [1, 3, 5], [2, 3, 5], [5, 3, 6], [5, 3, 7]]\n"
     ]
    }
   ],
   "source": [
    "gt_dir = \"api/test/new_prior_1500_GT\"\n",
    "class_file = gt_dir + \"/classes.txt\"\n",
    "\n",
    "\n",
    "def process_LLM_output(gt_dir=\"api/test/new_prior_1500_GT\", LLM_output=None):\n",
    "    \"\"\"\n",
    "    input\n",
    "    - gt_dir: location of the gt data directory\n",
    "    - LLM_output: the raw output of LLM, including step1,step2,step3\n",
    "\n",
    "    return\n",
    "    - room_list: a list of room class integer id\n",
    "    - adj_list: a list of room adjcency tuple- [room1 index, adj_id,room2 index]\n",
    "\n",
    "    \"\"\"\n",
    "    class_file = gt_dir + \"/classes.txt\"\n",
    "    rel_file = gt_dir + \"/relationships.txt\"\n",
    "    with open(class_file, \"r\") as f:\n",
    "        class_list = [line.rstrip() for line in f]\n",
    "        classes_dict = dict(zip(sorted(class_list), range(len(class_list))))\n",
    "\n",
    "    with open(rel_file, \"r\") as f:\n",
    "        rel_list = [line.strip().lower() for line in f]\n",
    "        rel_dict = dict(zip(rel_list, range(1, len(rel_list) + 1)))\n",
    "\n",
    "    room_str_list = LLM_output.step2\n",
    "    room_list = [classes_dict[rm] for rm in room_str_list]\n",
    "    adj_id = rel_dict.get(\"adjacent to\")\n",
    "    adj_list = [[adj.room1, adj_id, adj.room2] for adj in LLM_output.step3]\n",
    "\n",
    "    return room_list, adj_list\n",
    "\n",
    "\n",
    "room_list, adj_list = process_LLM_output(LLM_output=event)\n",
    "\n",
    "print(room_list)\n",
    "print(adj_list)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thesis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
