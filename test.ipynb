{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flask import Flask, request, jsonify\n",
    "import os\n",
    "import sys\n",
    "\n",
    "sys.path.append(\"./api\")\n",
    "from api.scripts.visualize_box_version import (\n",
    "    prepare_dataset_and_model,\n",
    "    generate_queried_unit_mesh,\n",
    ")\n",
    "\n",
    "args_location = \"api/test/new_prior_1500/args.json\"\n",
    "ckpt_link = (\n",
    "    \"https://drive.google.com/file/d/1-YjqqoAnv9_FD288mRYIGoNW75CcJaUR/view?usp=sharing\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_objs = [3, 13, 11]\n",
    "input_triples = [\n",
    "    [1, 3, 0],\n",
    "    [2, 3, 1],\n",
    "]\n",
    "unit_box = [3, 3, 5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model loaded!\n",
      "training statistics collected\n"
     ]
    }
   ],
   "source": [
    "args, model, dataset, _, _ = prepare_dataset_and_model(\n",
    "    args_location=args_location, ckpt_epoch=400, ckpt_link=ckpt_link\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['_unit_\\n', 'chair\\n', 'bathroom\\n', 'bed\\n', 'bedroom\\n', 'cabinet\\n', 'chair\\n', 'sofa\\n', 'chair\\n', 'circulation\\n', 'table\\n', 'courtyard\\n', 'desk\\n', 'chair\\n', 'table\\n', 'diningroom\\n', 'bed\\n', 'empty\\n', 'bed\\n', 'kitchen\\n', 'sofa\\n', 'library\\n', 'livingroom\\n', 'chair\\n', 'sofa\\n', 'sofa\\n', 'nightstand\\n', 'table\\n', 'service\\n', 'bed\\n', 'sofa\\n', 'storage\\n', 'table\\n', 'wardrobe\\n']\n"
     ]
    }
   ],
   "source": [
    "print(dataset.vocab[\"full_object_idx_to_name\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bed\n",
      "bathroom\n",
      "bedroom\n",
      "cabinet\n",
      "chair\n",
      "chair\n",
      "_unit_\n"
     ]
    }
   ],
   "source": [
    "detailed_obj_class = list(dataset.classes.keys())\n",
    "for idx in input_objs:\n",
    "    print(detailed_obj_class[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['_unit_', 'bathroom', 'bed', 'bedroom', 'cabinet', 'chair', 'circulation', 'courtyard', 'desk', 'diningroom', 'empty', 'kitchen', 'library', 'livingroom', 'nightstand', 'service', 'sofa', 'storage', 'table', 'wardrobe']\n",
      "tensor([ 2,  1,  3,  4,  5,  5,  0,  2, 14,  2,  8,  5,  2,  5, 14,  5,  5, 16,\n",
      "         0])\n",
      "tensor([ 0,  1,  2,  3,  4,  5,  6,  2,  2,  2,  2,  2,  6,  6,  6,  6,  6,  6,\n",
      "        18])\n",
      "bed\n",
      "bathroom\n",
      "bedroom\n",
      "cabinet\n",
      "chair\n",
      "chair\n",
      "_unit_\n",
      "_unit_\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'bed'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m model_file_path \u001b[38;5;241m=\u001b[39m \u001b[43mgenerate_queried_unit_mesh\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_objs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_objs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_triples\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_triples\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43munit_box\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43munit_box\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_dataset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      8\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[1;32me:\\neuralroom_nextjs\\api\\scripts\\visualize_box_version.py:335\u001b[0m, in \u001b[0;36mgenerate_queried_unit_mesh\u001b[1;34m(input_objs, input_triples, unit_box, args, model, train_dataset)\u001b[0m\n\u001b[0;32m    333\u001b[0m     fur_cat \u001b[38;5;241m=\u001b[39m json\u001b[38;5;241m.\u001b[39mload(file)\n\u001b[0;32m    334\u001b[0m \u001b[38;5;66;03m# trimesh mesh object\u001b[39;00m\n\u001b[1;32m--> 335\u001b[0m meshes, _, _ \u001b[38;5;241m=\u001b[39m \u001b[43mcreate_scene_meshes\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    336\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnew_objs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    337\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnew_obj2pidx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    338\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdenormalized_boxes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    339\u001b[0m \u001b[43m    \u001b[49m\u001b[43mangles_pred\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    340\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdetailed_obj_class\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    341\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfur_cat\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    342\u001b[0m \u001b[43m    \u001b[49m\u001b[43msdf_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    343\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretrieve_sdf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# export box only meshes\u001b[39;49;00m\n\u001b[0;32m    344\u001b[0m \u001b[43m    \u001b[49m\u001b[43mceiling_and_floor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    345\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    346\u001b[0m exp_dir \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(args[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexp\u001b[39m\u001b[38;5;124m\"\u001b[39m], \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmesh\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    347\u001b[0m mesh_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m.obj\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(data\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mscan_id\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n",
      "File \u001b[1;32me:\\neuralroom_nextjs\\./api\\helpers\\viz_util.py:842\u001b[0m, in \u001b[0;36mcreate_scene_meshes\u001b[1;34m(dec_objs_grained, obj_to_pidx, denormalized_boxes, angles_pred, detailed_obj_class, fur_cat, sdf_dir, retrieve_sdf, ceiling_and_floor, substract_room)\u001b[0m\n\u001b[0;32m    840\u001b[0m         unit_id \u001b[38;5;241m=\u001b[39m room_id\n\u001b[0;32m    841\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 842\u001b[0m         hier_id \u001b[38;5;241m=\u001b[39m \u001b[43mROOM_HIER_MAP\u001b[49m\u001b[43m[\u001b[49m\u001b[43mroom_class\u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m    843\u001b[0m         room_hier_dic[room_id] \u001b[38;5;241m=\u001b[39m hier_id\n\u001b[0;32m    844\u001b[0m room_idxs\u001b[38;5;241m.\u001b[39mremove(unit_id)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'bed'"
     ]
    }
   ],
   "source": [
    "model_file_path = generate_queried_unit_mesh(\n",
    "    input_objs=input_objs,\n",
    "    input_triples=input_triples,\n",
    "    unit_box=unit_box,\n",
    "    args=args,\n",
    "    model=model,\n",
    "    train_dataset=dataset,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 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\n",
    "# openai project key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatCompletionMessage(content=\"**Step 1: Determine Headcounts and Basic Room Requirements**\\n\\n- **Headcount Determination**:\\n  - Total permanent occupants: 4 people.\\n\\n- **Bedroom Requirements**:\\n  - Parents share 1 bedroom: 1 bedroom.\\n  - Each child has their own bedroom: 2 bedrooms.\\n  - Total bedrooms: 3 bedrooms (1 for parents, 1 for child 1, 1 for child 2).\\n\\n- **Bathroom Requirements**:\\n  - For 4 people, include at least 2 bathrooms for convenience.\\n  - Total bathrooms: 2 bathrooms.\\n\\n- **Basic Room List**:\\n['bedroom', 'bedroom', 'bedroom', 'bathroom', 'bathroom']\\n\\n**Step 2: Infer Additional Rooms**\\n\\n- **Livingroom**:\\n- Include 1 living room for family activities and gatherings.\\n\\n- **Kitchen**:\\n- Necessary for meal preparation.\\n\\n- **Diningroom**:\\n- Include 1 dining room for shared meals.\\n\\n- **Circulation**:\\n- Needed for connectivity throughout the home.\\n\\n- **Updated Room List**:\\n['bedroom', 'bedroom', 'bedroom', 'bathroom', 'bathroom', 'livingroom', 'kitchen', 'diningroom', 'circulation']\\n\\n**Step 3: Determine Room Adjacency**\\n\\n- **Assign Indexes**:\\nIndex Room Type \\n0 bedroom (parents) \\n1 bedroom (child 1) \\n2 bedroom (child 2) \\n3 bathroom \\n4 bathroom \\n5 livingroom \\n6 kitchen \\n7 diningroom \\n8 circulation\\n\\n- **Adjacency Analysis**:\\n- Bedrooms connected to bathrooms: (0, 3), (1, 4), (2, 4)\\n- All bedrooms connected to circulation (index 8): (0, 8), (1, 8), (2, 8)\\n- Circulation connected to livingroom (index 5): (8, 5)\\n- Livingroom connected to kitchen (index 6) and diningroom (index 7): (5, 6), (5, 7)\\n- Kitchen connected to diningroom: (6, 7)\\n\\n- **Adjacency List**:\\n[(0, 3), (1, 4), (2, 4), (0, 8), (1, 8), (2, 8), (8, 5), (5, 6), (5, 7), (6, 7)]\\n\\n**Step 4: Output the Room List and Adjacency List**\\n{\\n  'Room List': ['bedroom', 'bedroom', 'bedroom', 'bathroom', 'bathroom', 'livingroom', 'kitchen', 'diningroom', 'circulation'],\\n  'Adjacency List': [(0, 3), (1, 4), (2, 4), (0, 8), (1, 8), (2, 8), (8, 5), (5, 6), (5, 7), (6, 7)]\\n}\", refusal=None, role='assistant', function_call=None, tool_calls=None)\n"
     ]
    }
   ],
   "source": [
    "from api.LLM.prompt_basic import make_basic_input_prompt, make_basic_sysprompt\n",
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI()\n",
    "description = \"help me design a layout for a family of 4 -- one couple and two children. The couple shares a bedroom, and the each child has own bedroom\"\n",
    "sysprompt = make_basic_sysprompt()\n",
    "input = make_basic_input_prompt(description)\n",
    "\n",
    "completion = client.chat.completions.create(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": sysprompt},\n",
    "        {\"role\": \"user\", \"content\": input},\n",
    "    ],\n",
    ")\n",
    "print(completion.choices[0].message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step1=\"Total occupants: 4 persons. Bedrooms required: 1 (parents) + 2 (children) = 3 bedrooms. Bathrooms required: 2 for convenience. Basic Room List: ['bedroom', 'bedroom', 'bedroom', 'bathroom', 'bathroom']\" step2=\"Additional rooms needed: Livingroom (1), Kitchen (1 for meal preparation), Diningroom (1 for meals and gatherings). Updated Room List: ['bedroom', 'bedroom', 'bedroom', 'bathroom', 'bathroom', 'livingroom', 'kitchen', 'diningroom']\" step3='Assign Indexes: 0 (parents bedroom), 1 (child 1 bedroom), 2 (child 2 bedroom), 3 (bathroom 1), 4 (bathroom 2), 5 (livingroom), 6 (kitchen), 7 (diningroom). Adjacency Analysis: (0, 3), (1, 4), (2, 4), (0, 5), (1, 5), (2, 5), (5, 6), (5, 7), (6, 7). Adjacency List: [(0, 3), (1, 4), (2, 4), (0, 5), (1, 5), (2, 5), (5, 6), (5, 7), (6, 7)]' step4=RoomGraph(roomlist=['bedroom', 'bedroom', 'bedroom', 'bathroom', 'bathroom', 'livingroom', 'kitchen', 'diningroom'], adjacencylist=[RoomAdjacency(room1=0, room2=3), RoomAdjacency(room1=1, room2=4), RoomAdjacency(room1=2, room2=4), RoomAdjacency(room1=0, room2=5), RoomAdjacency(room1=1, room2=5), RoomAdjacency(room1=2, room2=5), RoomAdjacency(room1=5, room2=6), RoomAdjacency(room1=5, room2=7), RoomAdjacency(room1=6, room2=7)])\n"
     ]
    }
   ],
   "source": [
    "from pydantic import BaseModel\n",
    "from typing import List, Tuple\n",
    "\n",
    "\n",
    "from openai import OpenAI\n",
    "\n",
    "\n",
    "client = OpenAI()\n",
    "\n",
    "\n",
    "class RoomAdjacency(BaseModel):\n",
    "    room1: int\n",
    "    room2: int\n",
    "\n",
    "\n",
    "class RoomGraph(BaseModel):\n",
    "    roomlist: List[str]\n",
    "    adjacencylist: List[RoomAdjacency]\n",
    "\n",
    "\n",
    "class OutputGraph(BaseModel):\n",
    "    step1: str\n",
    "    step2: str\n",
    "    step3: str\n",
    "    step4: RoomGraph\n",
    "\n",
    "\n",
    "client = OpenAI()\n",
    "description = \"help me design a layout for a family of 4 -- one couple and two children. The couple shares a bedroom, and the each child has own bedroom\"\n",
    "sysprompt = make_basic_sysprompt()\n",
    "input = make_basic_input_prompt(description)\n",
    "\n",
    "\n",
    "completion = client.beta.chat.completions.parse(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": sysprompt},\n",
    "        {\"role\": \"user\", \"content\": input},\n",
    "    ],\n",
    "    response_format=OutputGraph,\n",
    ")\n",
    "\n",
    "\n",
    "event = completion.choices[0].message.parsed\n",
    "print(event)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "api/test/new_prior_1500_GT/classes.txt\n",
      "{'_unit_': 0, 'armchair': 1, 'bathroom': 2, 'bed': 3, 'bedroom': 4, 'cabinet': 5, 'chair': 6, 'chaise_longue_sofa': 7, 'chinese_chair': 8, 'circulation': 9, 'coffee_table': 10, 'courtyard': 11, 'desk': 12, 'dining_chair': 13, 'dining_table': 14, 'diningroom': 15, 'double_bed': 16, 'empty': 17, 'kids_bed': 18, 'kitchen': 19, 'l_shaped_sofa': 20, 'library': 21, 'livingroom': 22, 'lounge_chair': 23, 'loveseat_sofa': 24, 'multi_seat_sofa': 25, 'nightstand': 26, 'round_end_table': 27, 'service': 28, 'single_bed': 29, 'sofa': 30, 'storage': 31, 'table': 32, 'wardrobe': 33}\n",
      "[4, 4, 4, 2, 2, 22, 19, 15]\n",
      "3\n",
      "[[0, 3, 3], [1, 3, 4], [2, 3, 4], [0, 3, 5], [3, 3, 5], [5, 3, 6], [6, 3, 7]]\n",
      "process finished\n",
      "[4, 4, 4, 2, 2, 22, 19, 15]\n",
      "[[0, 3, 3], [1, 3, 4], [2, 3, 4], [0, 3, 5], [3, 3, 5], [5, 3, 6], [6, 3, 7]]\n"
     ]
    }
   ],
   "source": [
    "gt_dir = \"api/test/new_prior_1500_GT\"\n",
    "class_file = gt_dir + \"/classes.txt\"\n",
    "\n",
    "\n",
    "def process_LLM_output(classes_dict, rel_dict, LLM_output=None):\n",
    "    \"\"\"\n",
    "    input\n",
    "    - class_dic: the obj classes dict from the dataset\n",
    "    - rel_dic: the relationship dict from the dataset\n",
    "    - LLM_output: the raw output of LLM, including step1,step2,step3\n",
    "\n",
    "    return\n",
    "    - room_list: a list of room class integer id\n",
    "    - adj_list: a list of room adjcency tuple, (room1 index, room2 index)\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    room_str_list = LLM_output.step2\n",
    "    print(classes_dict)\n",
    "    room_list = [classes_dict[rm] for rm in room_str_list]\n",
    "    print(room_list)\n",
    "    adj_id = rel_dict.get(\"adjacent to\")\n",
    "    print(adj_id)\n",
    "    adj_list = [[adj.room1, adj_id, adj.room2] for adj in LLM_output.step3]\n",
    "    print(adj_list)\n",
    "    print(\"process finished\")\n",
    "    return room_list, adj_list\n",
    "\n",
    "\n",
    "room_list, adj_list = process_LLM_output(LLM_output=event)\n",
    "\n",
    "print(room_list)\n",
    "print(adj_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\neuralroom_nextjs\\api\\model\\VAE_prior.py:50: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  torch.load(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model loaded!\n",
      "training statistics collected\n",
      "model initialized\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "sys.path.append(\"api/\")\n",
    "\n",
    "from api.scripts.visualize_box_version import (\n",
    "    prepare_dataset_and_model,\n",
    "    generate_queried_unit_mesh,\n",
    ")\n",
    "\n",
    "\n",
    "gt_dir = \"api/test/new_prior_1500_GT\"\n",
    "args_location = \"api/test/new_prior_1500/args.json\"\n",
    "ckpt_link = (\n",
    "    \"https://drive.google.com/file/d/1-YjqqoAnv9_FD288mRYIGoNW75CcJaUR/view?usp=sharing\"\n",
    ")\n",
    "# model and dataset initialized when webpage mounted\n",
    "args, model, dataset, _, _ = prepare_dataset_and_model(\n",
    "    args_location=args_location, ckpt_epoch=400, ckpt_link=ckpt_link\n",
    ")\n",
    "print(\"model initialized\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'_unit_': 0, 'bathroom': 1, 'bed': 2, 'bedroom': 3, 'cabinet': 4, 'chair': 5, 'circulation': 6, 'courtyard': 7, 'desk': 8, 'diningroom': 9, 'empty': 10, 'kitchen': 11, 'library': 12, 'livingroom': 13, 'nightstand': 14, 'service': 15, 'sofa': 16, 'storage': 17, 'table': 18, 'wardrobe': 19}\n"
     ]
    }
   ],
   "source": [
    "print(dataset.classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index out of range in self",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m model_file_path \u001b[38;5;241m=\u001b[39m \u001b[43mgenerate_queried_unit_mesh\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_objs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mroom_list\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_triples\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43madj_list\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43munit_box\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_dataset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      8\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[1;32me:\\neuralroom_nextjs\\api\\scripts\\visualize_box_version.py:239\u001b[0m, in \u001b[0;36mgenerate_queried_unit_mesh\u001b[1;34m(input_objs, input_triples, unit_box, args, model, train_dataset)\u001b[0m\n\u001b[0;32m    232\u001b[0m dec_objs, dec_triples, dec_unit_box \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    233\u001b[0m     dec_objs\u001b[38;5;241m.\u001b[39mto(device),\n\u001b[0;32m    234\u001b[0m     dec_triples\u001b[38;5;241m.\u001b[39mto(device),\n\u001b[0;32m    235\u001b[0m     dec_unit_box\u001b[38;5;241m.\u001b[39mto(device),\n\u001b[0;32m    236\u001b[0m )\n\u001b[0;32m    237\u001b[0m seed \u001b[38;5;241m=\u001b[39m random\u001b[38;5;241m.\u001b[39mrandint(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m10000\u001b[39m)\n\u001b[1;32m--> 239\u001b[0m new_objs, new_triples, new_obj2pidx, boxes_pred, angles_pred \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvae_box\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minfer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    240\u001b[0m \u001b[43m    \u001b[49m\u001b[43mroom_nodes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdec_objs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    241\u001b[0m \u001b[43m    \u001b[49m\u001b[43mroom_triples\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdec_triples\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    242\u001b[0m \u001b[43m    \u001b[49m\u001b[43munit_box\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdec_unit_box\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    243\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrandom_seed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    244\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpoint_classes_idx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_dataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpoint_classes_idx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    245\u001b[0m \u001b[43m    \u001b[49m\u001b[43mwith_categories\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcategorize_latents\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    246\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    248\u001b[0m angle_num \u001b[38;5;241m=\u001b[39m args\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mangle_num\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m24\u001b[39m)\n\u001b[0;32m    250\u001b[0m angles_pred \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m180\u001b[39m \u001b[38;5;241m+\u001b[39m (torch\u001b[38;5;241m.\u001b[39margmax(angles_pred, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, keepdim\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m) \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m*\u001b[39m (\n\u001b[0;32m    251\u001b[0m     \u001b[38;5;241m360\u001b[39m \u001b[38;5;241m/\u001b[39m angle_num\n\u001b[0;32m    252\u001b[0m )\n",
      "File \u001b[1;32me:\\neuralroom_nextjs\\api\\model\\VAEGAN_V5BOX.py:596\u001b[0m, in \u001b[0;36mSg2ScVAEModel.infer\u001b[1;34m(self, room_nodes, room_triples, unit_box, device, random_seed, point_classes_idx, with_categories)\u001b[0m\n\u001b[0;32m    587\u001b[0m unit_z \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msample_latents(\n\u001b[0;32m    588\u001b[0m     torch\u001b[38;5;241m.\u001b[39mtensor([\u001b[38;5;241m0\u001b[39m])\u001b[38;5;241m.\u001b[39mto(device),\n\u001b[0;32m    589\u001b[0m     device\u001b[38;5;241m=\u001b[39mdevice,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    592\u001b[0m     with_categories\u001b[38;5;241m=\u001b[39mwith_categories,\n\u001b[0;32m    593\u001b[0m )\n\u001b[0;32m    594\u001b[0m \u001b[38;5;66;03m# no grad, reconstruct full graph\u001b[39;00m\n\u001b[0;32m    595\u001b[0m all_nodes, all_triples, all_zs, all_obj2pidx, roomunit_idxs, fur_idxs \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m--> 596\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreconstruct_full_graph\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    597\u001b[0m \u001b[43m        \u001b[49m\u001b[43mroom_nodes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mroom_nodes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    598\u001b[0m \u001b[43m        \u001b[49m\u001b[43mroom_triples\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mroom_triples\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    599\u001b[0m \u001b[43m        \u001b[49m\u001b[43mroom_zs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mroom_zs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    600\u001b[0m \u001b[43m        \u001b[49m\u001b[43munit_box\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43munit_box\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    601\u001b[0m \u001b[43m        \u001b[49m\u001b[43munit_z\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43munit_z\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    602\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    603\u001b[0m )\n\u001b[0;32m    605\u001b[0m roomunit_nodes \u001b[38;5;241m=\u001b[39m all_nodes[roomunit_idxs]\n\u001b[0;32m    606\u001b[0m all_unit_box \u001b[38;5;241m=\u001b[39m unit_box[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mrepeat((all_zs\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m), \u001b[38;5;241m1\u001b[39m))\u001b[38;5;241m.\u001b[39mto(device)\n",
      "File \u001b[1;32me:\\neuralroom_nextjs\\api\\model\\VAEGAN_V5BOX.py:836\u001b[0m, in \u001b[0;36mSg2ScVAEModel.reconstruct_full_graph\u001b[1;34m(self, room_nodes, room_triples, room_zs, unit_box, unit_z)\u001b[0m\n\u001b[0;32m    834\u001b[0m unitbox_vecs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39munit_box_embeddings_pr(unit_box)\n\u001b[0;32m    835\u001b[0m \u001b[38;5;66;03m# room semantic features\u001b[39;00m\n\u001b[1;32m--> 836\u001b[0m room_sem_vecs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msem_embeddings_rm_pr\u001b[49m\u001b[43m(\u001b[49m\u001b[43mroom_nodes\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    837\u001b[0m room_vecs \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat([room_sem_vecs, unitbox_vecs, room_zs], dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)  \u001b[38;5;66;03m# 2D\u001b[39;00m\n\u001b[0;32m    838\u001b[0m fur_z, fur_edges \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprior_sampler\u001b[38;5;241m.\u001b[39msample_fur_nodes(room_vecs)  \u001b[38;5;66;03m# 2 lists\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\moumo\\anaconda3\\envs\\neuralroom\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\moumo\\anaconda3\\envs\\neuralroom\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\moumo\\anaconda3\\envs\\neuralroom\\Lib\\site-packages\\torch\\nn\\modules\\sparse.py:164\u001b[0m, in \u001b[0;36mEmbedding.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    163\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 164\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membedding\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    165\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_norm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    166\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnorm_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscale_grad_by_freq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msparse\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\moumo\\anaconda3\\envs\\neuralroom\\Lib\\site-packages\\torch\\nn\\functional.py:2267\u001b[0m, in \u001b[0;36membedding\u001b[1;34m(input, weight, padding_idx, max_norm, norm_type, scale_grad_by_freq, sparse)\u001b[0m\n\u001b[0;32m   2261\u001b[0m     \u001b[38;5;66;03m# Note [embedding_renorm set_grad_enabled]\u001b[39;00m\n\u001b[0;32m   2262\u001b[0m     \u001b[38;5;66;03m# XXX: equivalent to\u001b[39;00m\n\u001b[0;32m   2263\u001b[0m     \u001b[38;5;66;03m# with torch.no_grad():\u001b[39;00m\n\u001b[0;32m   2264\u001b[0m     \u001b[38;5;66;03m#   torch.embedding_renorm_\u001b[39;00m\n\u001b[0;32m   2265\u001b[0m     \u001b[38;5;66;03m# remove once script supports set_grad_enabled\u001b[39;00m\n\u001b[0;32m   2266\u001b[0m     _no_grad_embedding_renorm_(weight, \u001b[38;5;28minput\u001b[39m, max_norm, norm_type)\n\u001b[1;32m-> 2267\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membedding\u001b[49m\u001b[43m(\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpadding_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscale_grad_by_freq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msparse\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mIndexError\u001b[0m: index out of range in self"
     ]
    }
   ],
   "source": [
    "model_file_path = generate_queried_unit_mesh(\n",
    "    input_objs=room_list,\n",
    "    input_triples=adj_list,\n",
    "    unit_box=[3, 3, 5],\n",
    "    args=args,\n",
    "    model=model,\n",
    "    train_dataset=dataset,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "neuralroom",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
